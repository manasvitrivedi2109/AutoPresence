<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AutoPresence - Face & Voice Recognition</title>
    <style>
        /* Your existing styles remain unchanged */
        body {
            background:-webkit-linear-gradient(left, #003366, #004080, #0059b3, #0073e6); 
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            margin: 0;
            font-family: 'Poppins', sans-serif;
            color: #fff;
        }
        .container {
            background: rgba(255, 255, 255, 0.95);
            padding: 40px;
            border-radius: 20px;
            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.3);
            text-align: center;
            width: 500px;
            animation: fadeIn 1s ease-in-out;
        }
        @keyframes fadeIn {
            from { opacity: 0; transform: scale(0.9); }
            to { opacity: 1; transform: scale(1); }
        }
        h1 {
            background:-webkit-linear-gradient(left, #003366,#004080,#0059b3
            , #0073e6);
            -webkit-background-clip: text;
            color: transparent;
            font-size: 28px;
        }
        p{
            background:-webkit-linear-gradient(left, #003366,#004080,#0059b3
            , #0073e6);
            -webkit-background-clip: text;
            color: transparent;
        }
        button {
            background: -webkit-linear-gradient(left, #003366, #004080, #0059b3, #0073e6);
            color: white;
            border: none;
            padding: 15px;
            margin: 20px 0;
            width: 90%;
            cursor: pointer;
            border-radius: 30px;
            font-size: 18px;
            font-weight: bold;
            transition: all 0.3s ease-in-out;
        }
        button:hover {
            background: linear-gradient(135deg, #0073E6, #00BFFF);
            transform: scale(1.08);
        }
        #status {
            font-size: 18px;
            margin-top: 15px;
            font-weight: bold;
            color: #0052A3;
        }
        #waveform {
            width: 100%;
            height: 100px;
            margin-top: 20px;
            background: #ffffff;
            border-radius: 10px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>AutoPresence</h1>
        <p>Use your voice for attendance marking.</p>
        <canvas id="waveform"></canvas>
        <button id="startRecording">üéô Start Voice Recognition</button>
        <p id="status">Click the button to start.</p>
    </div>

    <script type="module">
        // Firebase imports
        import { initializeApp } from "https://www.gstatic.com/firebasejs/10.7.1/firebase-app.js";
        import { getFirestore, collection, getDocs, addDoc, query, where } from "https://www.gstatic.com/firebasejs/10.7.1/firebase-firestore.js";

        // Firebase configuration
        const firebaseConfig = {
            apiKey: "AIzaSyCGiBeeTdmkRvjSXnjrmZp091w055lThMI",
            authDomain: "autopresence-b9594.firebaseapp.com",
            projectId: "autopresence-b9594",
            storageBucket: "autopresence-b9594.firebasestorage.app",
            messagingSenderId: "139292140260",
            appId: "1:139292140260:web:664258705e59f7ce7782f1"
        };

        // Initialize Firebase
        const app = initializeApp(firebaseConfig);
        const db = getFirestore(app);

        let recognitionActive = false;
        let animationId = null;

        // Start voice recognition
        document.getElementById("startRecording").addEventListener("click", () => {
            startVoiceRecognition();
            startAudioVisualization();
        });

        const canvas = document.getElementById("waveform");
        const ctx = canvas.getContext("2d");
        let audioContext, analyser, dataArray;

        async function startAudioVisualization() {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            analyser = audioContext.createAnalyser();
            const source = audioContext.createMediaStreamSource(stream);
            source.connect(analyser);
            analyser.fftSize = 64;
            const bufferLength = analyser.frequencyBinCount;
            dataArray = new Uint8Array(bufferLength);

            function draw() {
                if (!recognitionActive) {
                    cancelAnimationFrame(animationId);
                    return;
                }
                animationId = requestAnimationFrame(draw);
                analyser.getByteFrequencyData(dataArray);
                ctx.fillStyle = "#ffffff";
                ctx.fillRect(0, 0, canvas.width, canvas.height);
                const barWidth = (canvas.width / bufferLength) * 1.5;
                let x = 0;
                for (let i = 0; i < bufferLength; i++) {
                    const barHeight = dataArray[i] / 2;
                    ctx.fillStyle = "#0073E6";
                    ctx.fillRect(x, canvas.height - barHeight, barWidth, barHeight);
                    x += barWidth + 2;
                }
            }
            draw();
        }

        function startVoiceRecognition() {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!SpeechRecognition) {
                alert("Your browser does not support Speech Recognition. Use Google Chrome.");
                return;
            }

            const recognition = new SpeechRecognition();
            recognition.lang = "en-US";
            recognition.start();

            recognitionActive = true;

            recognition.onstart = () => {
                document.getElementById("status").innerText = "Listening...";
            };

            recognition.onresult = async (event) => {
                const transcript = event.results[0][0].transcript;
                document.getElementById("status").innerText = `You said: "${transcript}"`;

                // Time check logic here
                try {
                    const now = new Date();

                    // Define lecture time ranges
                    const lectureTimes = [
                        { start: "19:00", end: "21:20", lectureId: "Ai" }, // 2:10 PM to 3:10 PM
                        { start: "21:20", end: "21:30", lectureId: "Ns" }, // 3:10 PM to 4:10 PM
                        { start: "19:10", end: "21:20", lectureId: "Mad" },
                        { start: "21:20", end: "21:30", lectureId: "Mp" },
                        { start: "12:20", end: "13:30", lectureId: "Ai" }  // 7:10 PM to 9:20 PM
                    ];

                    let isWithinLectureTime = false;
                    let currentLectureId = null;

                    // Check if current time is within any of the defined lecture times
                    for (let { start, end, lectureId } of lectureTimes) {
                        const startTime = new Date();
                        const endTime = new Date();

                        const [startHour, startMinute] = start.split(":");
                        const [endHour, endMinute] = end.split(":");

                        startTime.setHours(startHour, startMinute, 0, 0);
                        endTime.setHours(endHour, endMinute, 0, 0);

                        if (now >= startTime && now <= endTime) {
                            isWithinLectureTime = true;
                            currentLectureId = lectureId;
                            break;
                        }
                    }

                    if (isWithinLectureTime) {
                        const matchedUser = await matchVoice(transcript);
                        if (matchedUser) {
                            await storeAttendance(matchedUser, now, currentLectureId);
                        } else {
                            document.getElementById("status").innerText = "‚ùå Voice Not Recognized!";
                        }
                    } else {
                        document.getElementById("status").innerText = "‚ùå Attendance only allowed during scheduled lecture times!";
                    }
                } catch (error) {
                    console.error("‚ùå Error storing attendance:", error);
                    document.getElementById("status").innerText = "‚ùå Error marking attendance!";
                }
            };

            recognition.onerror = (event) => {
                document.getElementById("status").innerText = "Error: " + event.error;
            };

            recognition.onend = () => {
                recognitionActive = false;
                document.getElementById("status").innerText += " (Recognition Ended)";
            };
        }

        async function matchVoice(userVoice) {
            try {
                const querySnapshot = await getDocs(collection(db, "voice_samples"));
                let matchedUser = null;

                querySnapshot.forEach((doc) => {
                    const storedVoice = doc.data().voiceText.toLowerCase().trim();
                    const spokenText = userVoice.toLowerCase().trim();

                    if (similarity(spokenText, storedVoice) > 0.85) {
                        matchedUser = doc.data().name;
                    }
                });

                return matchedUser;
            } catch (error) {
                console.error("‚ùå Error matching voice:", error);
                return null;
            }
        }

        async function storeAttendance(userName, timestamp, lectureId) {
            try {
                await addDoc(collection(db, "attendance"), {
                    timestamp: timestamp,
                    name: userName,
                    lectureId: lectureId,
                    attendanceType: "Ai"
                });
        
                // ‚úÖ Store successful voice recognition in sessionStorage
                sessionStorage.setItem("voiceRecognized", "true");
        
                // ‚úÖ Show success message
                document.getElementById("status").innerHTML = `‚úÖ Attendance Marked for <b>${userName}</b> in <b>${lectureId}</b> at ${timestamp.toLocaleTimeString()}`;
        
                // ‚úÖ Redirect after 3 seconds
                setTimeout(() => {
                    window.location.href = "camera_microphone.html"; 
                }, 3000); 
        
            } catch (error) {
                console.error("‚ùå Error storing attendance:", error);
                document.getElementById("status").innerHTML = "‚ùå Error marking attendance!";
            }
        }
        
        
        

        function similarity(a, b) {
            let longer = a;
            let shorter = b;
            if (a.length < b.length) {
                longer = b;
                shorter = a;
            }

            const longerLength = longer.length;
            if (longerLength === 0) {
                return 1.0;
            }

            return (longerLength - editDistance(longer, shorter)) / parseFloat(longerLength);
        }

        function editDistance(a, b) {
            a = a.toLowerCase();
            b = b.toLowerCase();

            const matrix = [];
            let i, j;

            for (i = 0; i <= a.length; i++) {
                matrix[i] = [i];
            }
            for (j = 0; j <= b.length; j++) {
                matrix[0][j] = j;
            }

            for (i = 1; i <= a.length; i++) {
                for (j = 1; j <= b.length; j++) {
                    const cost = a[i - 1] === b[j - 1] ? 0 : 1;
                    matrix[i][j] = Math.min(matrix[i - 1][j] + 1, matrix[i][j - 1] + 1, matrix[i - 1][j - 1] + cost);
                }
            }

            return matrix[a.length][b.length];
        }
    </script>
</body>
</html>
