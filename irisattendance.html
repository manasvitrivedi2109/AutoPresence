<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Recognition</title>
    <script defer src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
    <style>
        body { text-align: center; font-family: Arial, sans-serif; }
        video { border: 2px solid black; margin-top: 10px; }
        canvas { position: absolute; top: 0; left: 0; }
    </style>
</head>
<body>
    <h2>Face Recognition System</h2>
    <video id="video" width="640" height="480" autoplay></video>
    <p id="status">Loading models...</p>

    <script>
        const video = document.getElementById('video');
        let faceMatcher;

        async function loadModels() {
            await faceapi.nets.tinyFaceDetector.loadFromUri('/models');
            await faceapi.nets.faceLandmark68Net.loadFromUri('/models');
            await faceapi.nets.faceRecognitionNet.loadFromUri('/models');
            console.log("Models Loaded!");

            // Load stored face descriptors
            const response = await fetch('faceDescriptors.json');
            const storedData = await response.json();
            
            // Convert stored descriptors into FaceMatcher format
            const labeledDescriptors = storedData.map(user => 
                new faceapi.LabeledFaceDescriptors(
                    user.label, 
                    user.descriptors.map(d => new Float32Array(d))
                )
            );

            faceMatcher = new faceapi.FaceMatcher(labeledDescriptors);
            document.getElementById("status").innerText = "Models Loaded! Start Recognizing...";
        }

        async function startVideo() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
                video.srcObject = stream;
            } catch (err) {
                console.error("Camera access denied!", err);
            }
        }

        video.addEventListener('play', async () => {
            const canvas = faceapi.createCanvasFromMedia(video);
            document.body.append(canvas);
            const displaySize = { width: video.width, height: video.height };
            faceapi.matchDimensions(canvas, displaySize);

            setInterval(async () => {
                const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
                    .withFaceLandmarks()
                    .withFaceDescriptors();

                const resizedDetections = faceapi.resizeResults(detections, displaySize);
                canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
                faceapi.draw.drawDetections(canvas, resizedDetections);
                faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);

                if (detections.length > 0) {
                    const bestMatch = faceMatcher.findBestMatch(detections[0].descriptor);
                    document.getElementById("status").innerText = `Face Matched: ${bestMatch.toString()}`;
                } else {
                    document.getElementById("status").innerText = "No face detected.";
                }
            }, 1000);
        });

        loadModels();
        startVideo();
    </script>
</body>
</html>
